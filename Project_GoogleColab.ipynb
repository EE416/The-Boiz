{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Project.ipynb","provenance":[{"file_id":"https://github.com/EE416/The-Boiz/blob/main/Project.ipynb","timestamp":1606044655949}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"uHLl1yPMplue"},"source":["import random\n","import csv\n","import os\n","import os.path\n","import shutil\n","import cv2\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm # Displays a progress bar\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torch.utils.data import Dataset, Subset, DataLoader, random_split\n","\n","import pandas as pd\n","import h5py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WF_DuRGJqmfo"},"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","!gdown https://drive.google.com/uc?id=1olKESqgAm5GeAmuRC21BpTBkxFrgmUIp\n","!unzip /content/Data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KpjDNBt5-aqu","executionInfo":{"status":"ok","timestamp":1606118707118,"user_tz":600,"elapsed":8597,"user":{"displayName":"Keenan Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8Wki9e0tZQDtTmt29KDphWhpTz1T0fjLgOarU6Q=s64","userId":"17155771245047856139"}}},"source":["class DataNonNorm:\n","    def __init__(self, root):\n","        self.ROOT = root\n","        self.images = self.read_images(os.path.join(root, \"Images\"))\n","        self.labels = self.read_labels(os.path.join(root, \"Labels\"))\n","\n","    def __len__(self):\n","        # Return number of points in the dataset\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        # Here we have to return the item requested by `idx`. The PyTorch DataLoader class will use this method to make an iterable for training/validation loop.\n","        img = self.images[idx] / 255\n","        #label = self.labels[idx]\n","        return img\n","  \n","    # Read Images\n","    def read_images(self, path:str) -> list:\n","        imgs = []\n","        with h5py.File(os.path.join(path, \"imagedata.hdf5\"), \"r\") as f:\n","            for i in sorted(f.keys(), key = int ):\n","                imgs.append(np.array(f.get(str(i))))\n","        #output = torch.tensor(output)\n","        return imgs\n","      \n","    # Read Labels\n","    def read_labels(self, path:str) -> list:\n","        output = []\n","        with h5py.File(os.path.join(path, \"labeldata.hdf5\"), \"r\") as f:\n","            labels = f[\"labels\"][()]\n","        return labels       \n","\n","# # Load the dataset and train and test splits\n","# print(\"Loading datasets...\")\n","\n","# # Data path\n","dataTrain = DataNonNorm(os.path.normpath('./Data/Train'))\n","dataTest  = DataNonNorm(os.path.normpath('./Data/Test'))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"IRne1h7R_oQg","executionInfo":{"status":"ok","timestamp":1606118710471,"user_tz":600,"elapsed":1360,"user":{"displayName":"Keenan Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8Wki9e0tZQDtTmt29KDphWhpTz1T0fjLgOarU6Q=s64","userId":"17155771245047856139"}}},"source":["trainloader = DataLoader(dataTrain, batch_size=32, shuffle=True)\n","testloader = DataLoader(dataTest, batch_size=2, shuffle=True)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVcYbvAO-mk9","executionInfo":{"status":"ok","timestamp":1606119235820,"user_tz":600,"elapsed":31677,"user":{"displayName":"Keenan Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8Wki9e0tZQDtTmt29KDphWhpTz1T0fjLgOarU6Q=s64","userId":"17155771245047856139"}},"outputId":"3507c6da-e443-4a46-8ee9-7023e99ebd82"},"source":["import math\n","# Get mean and std deviation of training and test\n","tnMean = 0.\n","tnStd = 0.\n","count = 0.\n","var = 0.\n","for data in trainloader:\n","    tnMean += np.mean(np.array(data))\n","    var += np.var(np.array(data))\n","    count += 1\n","\n","tnMean /= count\n","tnStd = math.sqrt(var / count)\n","\n","print(tnMean)\n","print(tnStd)\n","\n","tstMean = 0.\n","tstStd = 0.\n","count = 0.\n","var = 0.\n","for data in testloader:\n","    tstMean += np.mean(np.array(data))\n","    var += np.var(np.array(data))\n","    count += 1\n","\n","tstMean /= count\n","tstStd = math.sqrt(var / count)\n","\n","print(tstMean)\n","print(tstStd)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["0.6531141332511887\n","0.26932273407019464\n","0.6535949342601184\n","0.2643014432779285\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IBy7YEltplue"},"source":["class Data:\n","\n","    def __init__(self, root, mn, std):\n","        self.ROOT = root\n","        self.images = self.read_images(os.path.join(root, \"Images\"))\n","        self.labels = self.read_labels(os.path.join(root, \"Labels\"))\n","\n","        self.transform = MyTransform = transforms.Compose([\n","            transforms.ToTensor(), # Transform from [0,255] uint8 to [0,1] float\n","            transforms.Normalize((mn, mn, mn), (std, std, std)) # TODO: Normalize to zero mean and unit variance with appropriate parameters 0.5\n","            ])\n","\n","    def __len__(self):\n","        # Return number of points in the dataset\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        # Here we have to return the item requested by `idx`. The PyTorch DataLoader class will use this method to make an iterable for training/validation loop.\n","        img = self.transform(self.images[idx])\n","        # img = self.images[idx] / 255\n","        label = self.labels[idx]\n","        return img, label\n","  \n","    # Read Images\n","    def read_images(self, path:str) -> list:\n","        imgs = []\n","        with h5py.File(os.path.join(path, \"imagedata.hdf5\"), \"r\") as f:\n","            for i in sorted(f.keys(), key = int ):\n","                imgs.append(np.array(f.get(str(i))))\n","        #output = torch.tensor(output)\n","        return imgs\n","      \n","    # Read Labels\n","    def read_labels(self, path:str) -> list:\n","        output = []\n","        with h5py.File(os.path.join(path, \"labeldata.hdf5\"), \"r\") as f:\n","            labels = f[\"labels\"][()]\n","        return labels       \n","\n","# Load the dataset and train and test splits\n","print(\"Loading datasets...\")\n","\n","# Data path\n","dataTrain = Data(os.path.normpath('./Data/Train'), tnMean, tnStd)\n","dataTest  = Data(os.path.normpath('./Data/Test'),tstMean, tstStd)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wCnEOl_0plue"},"source":["print(dataTrain.__len__())\n","print(len(dataTrain.labels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OmzaFVlM-at7"},"source":["from PIL import Image\n","\n","with h5py.File(os.path.join('./Data/Train/Images', \"imagedata.hdf5\"), \"r\") as f:\n","  img = Image.fromarray(np.array(f.get(\"1\")))\n","display(img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Z5bXQC2plue"},"source":["# print(\"Done!\")\n","\n","# # Create dataloaders\n","# # TODO: Experiment with different batch sizes\n","trainloader = DataLoader(dataTrain, batch_size=32, shuffle=True, drop_last=True)\n","testloader = DataLoader(dataTest, batch_size=2, shuffle=True, drop_last=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHdKPym7plue"},"source":["from torchvision import datasets, transforms\n","import torchvision.models as models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"32EIpR-Xplue"},"source":["class Network(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # TODO: [Transfer learning with pre-trained ResNet-50] 1) Define how many first layers of convolutoinal neural network (CNN) feature extractor in ResNet-50 to be \"frozen\" and 2) design your own fully-connected network (FCN) classifier.\n","        # 1) You will only refine last several layers of CNN feature extractor in ResNet-50 that mainly relate to high-level vision task. Determine how many first layers of ResNet-50 should be frozen to achieve best performances. Commented codes below will help you understand the architecture, i.e., \"children\", of ResNet-50.\n","        # 2) Design your own FCN classifier. Here I provide a sample of two-layer FCN.\n","        # Refer to PyTorch documentations of torch.nn to pick your layers. (https://pytorch.org/docs/stable/nn.html)\n","        # Some common Choices are: Linear, ReLU, Dropout, MaxPool2d, AvgPool2d\n","        # If you have many layers, consider using nn.Sequential() to simplify your code\n","        \n","        # Load pretrained ResNet-50\n","        self.model_resnet = models.resnet50(pretrained=True)\n","        \n","        # The code below can show children of ResNet-50\n","        # child_counter = 0\n","        # for child in model.children():\n","        #    print(\" child\", child_counter, \"is -\")\n","        #    print(child)\n","        #    child_counter += 1\n","        \n","        # TODO: Determine how many first layers of ResNet-50 to freeze\n","        child_counter = 0\n","        for child in self.model_resnet.children():\n","            if child_counter < 6:\n","                for param in child.parameters():\n","                    param.requires_grad = False\n","            elif child_counter == 6:\n","                children_of_child_counter = 0\n","                for children_of_child in child.children():\n","                    if children_of_child_counter < 3:\n","                        for param in children_of_child.parameters():\n","                            param.requires_grad = False\n","                    else:\n","                        children_of_child_counter += 1\n","            else:\n","                print(\"child \",child_counter,\" was not frozen\")\n","            child_counter += 1\n","        \n","        # Set ResNet-50's FCN as an identity mapping\n","        num_fc_in = self.model_resnet.fc.in_features\n","        self.model_resnet.fc = nn.Identity()\n","        \n","        # TODO: Design your own FCN\n","        self.fc1 = nn.Linear(num_fc_in, 20, bias = 3) # from input of size num_fc_in to output of size ?\n","        self.bn1 = nn.BatchNorm1d(num_features=20)\n","        self.fc2 = nn.Linear(20, 3, bias = 3) # from hidden layer to 3 class scores\n","\n","    def forward(self,x):\n","        # TODO: Design your own network, implement forward pass here\n","        \n","        relu = nn.ReLU() # No need to define self.relu because it contains no parameters\n","        \n","        with torch.no_grad():\n","            features = self.model_resnet(x)\n","            \n","        x = self.fc1(features) # Activation are flattened before being passed to the fully connected layers\n","        x = self.bn1(x)\n","        x = relu(x)\n","        x = self.fc2(x)\n","        \n","        # The loss layer will be applied outside Network class\n","        return x\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Configure device\n","model= Network().to(device)\n","criterion = nn.CrossEntropyLoss() # Specify the loss layer (note: CrossEntropyLoss already includes LogSoftMax())\n","# TODO: Modify the line below, experiment with different optimizers and parameters (such as learning rate)\n","optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=.001, weight_decay=0.004) # Specify optimizer and assign trainable parameters to it, weight_decay is L2 regularization strength (default: lr=1e-2, weight_decay=1e-4)\n","num_epochs = 30 # TODO: Choose an appropriate number of training epochs\n","\n","def train(model, loader, num_epoch = num_epochs): # Train the model\n","    print(\"Start training...\")\n","    model.train() # Set the model to training mode\n","    for i in range(num_epoch):\n","        running_loss = []\n","        for batch, label in tqdm(loader, position=0, leave=True):\n","            batch = batch.to(device)\n","            label = label.to(device)\n","            optimizer.zero_grad() # Clear gradients from the previous iteration\n","            pred = model(batch) # This will call Network.forward() that you implement\n","            loss = criterion(pred, label) # Calculate the loss\n","            running_loss.append(loss.item())\n","            loss.backward() # Backprop gradients to all tensors in the network\n","            optimizer.step() # Update trainable weights\n","        print(\"Epoch {} loss:{}\".format(i+1,np.mean(running_loss))) # Print the average loss for this epoch\n","    print(\"Done!\")\n","\n","def evaluate(model, loader): # Evaluate accuracy on validation / test set\n","    model.eval() # Set the model to evaluation mode\n","    correct = 0\n","    with torch.no_grad(): # Do not calculate grident to speed up computation\n","        for batch, label in tqdm(loader, position=0, leave=True):\n","            batch = batch.to(device)\n","            label = label.to(device)\n","            pred = model(batch)\n","            correct += (torch.argmax(pred,dim=1)==label).sum().item()\n","    acc = correct/len(loader.dataset)\n","    print(\"Evaluation accuracy: {}\".format(acc))\n","    return acc\n","    \n","train(model, trainloader, num_epochs)\n","print(\"Evaluate on test set\")\n","evaluate(model, testloader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e78Xbvgc58kZ"},"source":["# Load pretrained ResNet-50\n","model_resnet = models.resnet50(pretrained=True)\n","\n","# The code below can show children of ResNet-50\n","child_counter = 0\n","for child in model_resnet.children():\n","    print(\" child\", child_counter, \"is -\")\n","    print(child)\n","    child_counter += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S0dDB9m1plue"},"source":[""],"execution_count":null,"outputs":[]}]}