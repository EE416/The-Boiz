{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed2d73b4a1c545d3b37c7d0d1804fff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_82a6b6b036974189940f6d7165051054",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d8b2c3d9a5d4bab9264e36bda033499",
              "IPY_MODEL_175a93c8275e48b7b68ee3243666e3d6"
            ]
          }
        },
        "82a6b6b036974189940f6d7165051054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d8b2c3d9a5d4bab9264e36bda033499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a9d46e066b244cad9cd053d20ab1ff2c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ce8fe286f3c4a4a82a1ecd7c1a4d281"
          }
        },
        "175a93c8275e48b7b68ee3243666e3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_238951c9d0a74de387033fdadb06ce21",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 149MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10fd6d5b32584b859f656c76503fc85c"
          }
        },
        "a9d46e066b244cad9cd053d20ab1ff2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ce8fe286f3c4a4a82a1ecd7c1a4d281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "238951c9d0a74de387033fdadb06ce21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10fd6d5b32584b859f656c76503fc85c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUDCSCIUr_a7"
      },
      "source": [
        "import random\n",
        "import csv\n",
        "import os\n",
        "import os.path\n",
        "import shutil\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm # Displays a progress bar\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, Subset, DataLoader, random_split\n",
        "import torchvision.models as models\n",
        "\n",
        "import pandas as pd\n",
        "import h5py"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDc9L7um4zYH",
        "outputId": "e8a8902e-07c3-4dd1-fb45-8ae495540f7e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "!gdown https://drive.google.com/file/d/1olKESqgAm5GeAmuRC21BpTBkxFrgmUIp/view?usp=sharing\n",
        "!unzip /content/drive/MyDrive/EE416/Data\n",
        "%cd /content/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n",
            "/usr/local/lib/python2.7/dist-packages/gdown/parse_url.py:31: UserWarning: You specified Google Drive Link but it is not the correct link to download the file. Maybe you should try: https://drive.google.com/uc?id=1olKESqgAm5GeAmuRC21BpTBkxFrgmUIp\n",
            "  .format(url='https://drive.google.com/uc?id={}'.format(file_id))\n",
            "Downloading...\n",
            "From: https://drive.google.com/file/d/1olKESqgAm5GeAmuRC21BpTBkxFrgmUIp/view?usp=sharing\n",
            "To: /content/view?usp=sharing\n",
            "62.0kB [00:00, 4.14MB/s]\n",
            "Archive:  /content/drive/MyDrive/EE416/Data.zip\n",
            "   creating: Data/Test/\n",
            "   creating: Data/Test/Images/\n",
            "  inflating: Data/Test/Images/imagedata.hdf5  \n",
            "   creating: Data/Test/Labels/\n",
            "  inflating: Data/Test/Labels/labeldata.hdf5  \n",
            "   creating: Data/Train/\n",
            "   creating: Data/Train/Images/\n",
            "  inflating: Data/Train/Images/imagedata.hdf5  \n",
            "   creating: Data/Train/Labels/\n",
            "  inflating: Data/Train/Labels/labeldata.hdf5  \n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Data:\n",
    "\n",
    "    def __init__(self, root):\n",
    "\n",
    "        self.ROOT = root\n",
    "        self.images = self.read_images(root + \"/image\")\n",
    "        self.labels = self.read_labels(root + \"/label\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return number of points in the dataset\n",
    "\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Here we have to return the item requested by `idx`. The PyTorch DataLoader class will use this method to make an iterable for training/validation loop.\n",
    "\n",
    "        img = images[idx]\n",
    "        label = labels[idx]\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "    # Read Images\n",
    "    def read_images(self, path:str) -> list:\n",
    "        output = []\n",
    "        for file in sorted(os.listdir(path), key=lambda f : int(f[:-4])):\n",
    "            if file.endswith(\".png\"):\n",
    "                dir_path = os.path.join(path, file)\n",
    "                img = cv2.imread(dir_path)   \n",
    "                output.append(img)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    # Read Labels\n",
    "    def read_labels(self, path:str) -> list:\n",
    "        output = []\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith(\".csv\"):\n",
    "                file = os.path.join(path, file)\n",
    "                df = pd.read_csv(file)\n",
    "                output = df.label #you can also use df['column_name']\n",
    "            \n",
    "        return output       \n",
    "\n",
    "# Load the dataset and train and test splits\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# Data path\n",
    "TrainData = Data('./Dataset/Train')\n",
    "TestData = Data('./Dataset/Test')\n",
    "\n",
    "######################################################\n",
    "# Save data into binary files so we can just load them\n",
    "######################################################\n",
    "# Delete Dataset Folder\n",
    "dtpath = os.path.normpath('./Data')\n",
    "tnImg  = os.path.join(dtpath, 'Train/images')\n",
    "tnLbl  = os.path.join(dtpath, 'Train/labels')\n",
    "tstImg = os.path.join(dtpath, 'Test/images')\n",
    "tstLbl = os.path.join(dtpath, 'Test/labels')\n",
    "\n",
    "if os.path.exists():\n",
    "    print('Removing old data')\n",
    "    shutil.rmtree(dtset) \n",
    "\n",
    "# Create new directory\n",
    "os.makedirs(tnImg)\n",
    "os.makedirs(tnLbl)\n",
    "os.makedirs(tstImg)\n",
    "os.makedirs(tstLbl)\n",
    "\n",
    "# For TrainData\n",
    "# Images\n",
    "with h5py.File(os.path.join(tnImg, \"imagedata.hdf5\"), \"w\") as data_file:\n",
    "    for i,image in enumerate(TrainData.images):\n",
    "        data_file.create_dataset(str(i), data=image)\n",
    "# Labels\n",
    "with h5py.File(os.path.join(tnLbl, \"labeldata.hdf5\"), \"w\") as data_file:\n",
    "    data_file.create_dataset(\"labels\", data=TrainData.labels)\n",
    "\n",
    "# For TestData\n",
    "# Images\n",
    "with h5py.File(os.path.join(tstImg, \"imagedata.hdf5\"), \"w\") as data_file:\n",
    "    for i,image in enumerate(TestData.images):\n",
    "        data_file.create_dataset(str(i), data=image)\n",
    "# Labels\n",
    "with h5py.File(os.path.join(tstLbl, \"labeldata.hdf5\"), \"w\") as data_file:\n",
    "    data_file.create_dataset(\"labels\", data=TestData.labels)\n",
    "    \n",
    "# # Data normalization\n",
    "# MyTransform = transforms.Compose([\n",
    "#     transforms.Grayscale(num_output_channels=1), # Convert image to grayscale\n",
    "#     transforms.ToTensor(), # Transform from [0,255] uint8 to [0,1] float\n",
    "#     transforms.Normalize([0.1], [0.2] ) # TODO: Normalize to zero mean and unit variance with appropriate parameters\n",
    "# ])\n",
    "\n",
    "# DATA_train = datasets.ImageFolder(root=DATA_train_path, transform=MyTransform)\n",
    "# DATA_test = datasets.ImageFolder(root=DATA_test_path, transform=MyTransform)\n",
    "\n",
    "# print(\"Done!\")\n",
    "\n",
    "# # Create dataloaders\n",
    "# # TODO: Experiment with different batch sizes\n",
    "trainloader = DataLoader(Data_train, batch_size=1, shuffle=True)\n",
    "testloader = DataLoader(Data_test, batch_size=2, shuffle=True)\n",
    "\n",
    "# print(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "\n",
    "    def __init__(self, root):\n",
    "        self.ROOT = root\n",
    "        self.images = self.read_images(os.path.join(root, \"images\"))\n",
    "        self.labels = self.read_labels(os.path.join(root, \"labels\"))\n",
    "\n",
    "        self.transform = MyTransform = transforms.Compose([\n",
    "            transforms.ToTensor(), # Transform from [0,255] uint8 to [0,1] float\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # TODO: Normalize to zero mean and unit variance with appropriate parameters 0.5\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return number of points in the dataset\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Here we have to return the item requested by `idx`. The PyTorch DataLoader class will use this method to make an iterable for training/validation loop.\n",
    "        img = self.transform(self.images[idx])\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "  \n",
    "    # Read Images\n",
    "    def read_images(self, path:str) -> list:\n",
    "        imgs = []\n",
    "        with h5py.File(os.path.join(path, \"imagedata.hdf5\"), \"r\") as f:\n",
    "            for i in sorted(f.keys(), key = int ):\n",
    "                imgs.append(np.array(f.get(str(i))))\n",
    "        #output = torch.tensor(output)\n",
    "        return imgs\n",
    "      \n",
    "    # Read Labels\n",
    "    def read_labels(self, path:str) -> list:\n",
    "        output = []\n",
    "        with h5py.File(os.path.join(path, \"labeldata.hdf5\"), \"r\") as f:\n",
    "            labels = f[\"labels\"][()]\n",
    "        return labels       \n",
    "\n",
    "# # Load the dataset and train and test splits\n",
    "# print(\"Loading datasets...\")\n",
    "\n",
    "# # Data path\n",
    "dataTrain = Data(os.path.normpath('./Data/Train'))\n",
    "dataTest  = Data(os.path.normpath('./Data/Test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CozGdeEXr_a8"
      },
      "source": [
        "class Data:\n",
        "\n",
        "    def __init__(self, root):\n",
        "        self.ROOT = root\n",
        "        self.images = self.read_images(os.path.join(root, \"Images\"))\n",
        "        self.labels = self.read_labels(os.path.join(root, \"Labels\"))\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            # Transform from [0,255] uint8 to [0,1] float\n",
        "            transforms.ToTensor(), \n",
        "            # ===============================================\n",
        "            # Normalize to zero mean and unit variance with appropriate parameters 0.5\n",
        "            # ===============================================\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
        "            ])\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return number of points in the dataset\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Here we have to return the item requested by `idx`. The PyTorch DataLoader class will use this method to make an iterable for training/validation loop.\n",
        "        img = self.transform(self.images[idx])\n",
        "        label = self.labels[idx]\n",
        "        return img, label\n",
        "  \n",
        "    # Read Images\n",
        "    def read_images(self, path:str) -> list:\n",
        "        imgs = []\n",
        "        with h5py.File(os.path.join(path, \"imagedata.hdf5\"), \"r\") as f:\n",
        "            for i in sorted(f.keys(), key = int ):\n",
        "                imgs.append(np.array(f.get(str(i))))\n",
        "        #output = torch.tensor(output)\n",
        "        return imgs\n",
        "      \n",
        "    # Read Labels\n",
        "    def read_labels(self, path:str) -> list:\n",
        "        output = []\n",
        "        with h5py.File(os.path.join(path, \"labeldata.hdf5\"), \"r\") as f:\n",
        "            labels = f[\"labels\"][()]\n",
        "        return labels       \n",
        "\n",
        "# Load the dataset and train and test splits\n",
        "print(\"Loading datasets...\")\n",
        "\n",
        "# Data path\n",
        "dataTrain = Data(os.path.normpath('./Data/Train'))\n",
        "dataTest  = Data(os.path.normpath('./Data/Test'))\n",
        "\n",
        "print(\"Done!\")\n",
        "\n",
        "# Create dataloaders\n",
        "########################################################\n",
        "# Experiment with different batch sizes\n",
        "########################################################\n",
        "trainloader = DataLoader(dataTrain, batch_size=1, shuffle=True)\n",
        "testloader = DataLoader(dataTest, batch_size=2, shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sis2VpK9r_a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445,
          "referenced_widgets": [
            "ed2d73b4a1c545d3b37c7d0d1804fff0",
            "82a6b6b036974189940f6d7165051054",
            "4d8b2c3d9a5d4bab9264e36bda033499",
            "175a93c8275e48b7b68ee3243666e3d6",
            "a9d46e066b244cad9cd053d20ab1ff2c",
            "6ce8fe286f3c4a4a82a1ecd7c1a4d281",
            "238951c9d0a74de387033fdadb06ce21",
            "10fd6d5b32584b859f656c76503fc85c"
          ]
        },
        "outputId": "43363ee2-2f3b-47d0-f8b1-4e0e0c016ee9"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # TODO: [Transfer learning with pre-trained ResNet-50] \n",
        "        # 1) Define how many first layers of convolutoinal neural network (CNN) feature extractor in ResNet-50 to be \"frozen\" and \n",
        "        # 2) design your own fully-connected network (FCN) classifier.\n",
        "        \n",
        "        # 1) You will only refine last several layers of CNN feature extractor in ResNet-50 that mainly relate to high-level vision task. Determine how many first layers of ResNet-50 should be frozen to achieve best performances. Commented codes below will help you understand the architecture, i.e., \"children\", of ResNet-50.\n",
        "        # 2) Design your own FCN classifier. Here I provide a sample of two-layer FCN.\n",
        "        # Refer to PyTorch documentations of torch.nn to pick your layers. (https://pytorch.org/docs/stable/nn.html)\n",
        "        # Some common Choices are: Linear, ReLU, Dropout, MaxPool2d, AvgPool2d\n",
        "        # If you have many layers, consider using nn.Sequential() to simplify your code\n",
        "        \n",
        "        # Load pretrained ResNet-50\n",
        "        self.model_resnet = models.resnet50(pretrained=True)\n",
        "        \n",
        "        # The code below can show children of ResNet-50\n",
        "        #child_counter = 0\n",
        "        #for child in model.children():\n",
        "        #    print(\" child\", child_counter, \"is -\")\n",
        "        #    print(child)\n",
        "        #    child_counter += 1\n",
        "        \n",
        "        # ==================================================================\n",
        "        # [Transfer learning with pre-trained ResNet-50] \n",
        "        # ==================================================================\n",
        "\n",
        "        # ==================================================================\n",
        "        # Determine how many first layers of ResNet-50 to freeze\n",
        "        # ==================================================================\n",
        "        '''\n",
        "          How to decide how many layers to freeze?\n",
        "        '''\n",
        "\n",
        "        child_counter = 0\n",
        "        for child in self.model_resnet.children():\n",
        "            if child_counter < 5:\n",
        "                for param in child.parameters():\n",
        "                    param.requires_grad = False\n",
        "            elif child_counter == 5:\n",
        "                children_of_child_counter = 0\n",
        "                for children_of_child in child.children():\n",
        "                    if children_of_child_counter < 2:\n",
        "                        for param in children_of_child.parameters():\n",
        "                            param.requires_grad = False\n",
        "                    else:\n",
        "                        children_of_child_counter += 1\n",
        "            else:\n",
        "                print(\"child \",child_counter,\" was not frozen\")\n",
        "            child_counter += 1\n",
        "        \n",
        "        # Set ResNet-50's FCN as an identity mapping\n",
        "        num_fc_in = self.model_resnet.fc.in_features\n",
        "        self.model_resnet.fc = nn.Identity()\n",
        "        \n",
        "        # ==================================================================\n",
        "        # Design your own FCN\n",
        "        # ==================================================================\n",
        "        self.fc1 = nn.Linear(num_fc_in, 64, bias = 3) # from input of size num_fc_in to output of size ?\n",
        "        self.fc2 = nn.Linear(64, 3, bias = 3) # from hidden layer to 3 class scores\n",
        "\n",
        "    def forward(self,x):\n",
        "        # ==================================================================\n",
        "        # Design your own network, implement forward pass here\n",
        "        # ==================================================================\n",
        "        \n",
        "        relu = nn.ReLU() # No need to define self.relu because it contains no parameters\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            features = self.model_resnet(x)\n",
        "            \n",
        "        x = self.fc1(features) # Activation are flattened before being passed to the fully connected layers\n",
        "        x = relu(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        # The loss layer will be applied outside Network class\n",
        "        return x\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Configure device\n",
        "model= Network().to(device)\n",
        "criterion = nn.CrossEntropyLoss() # Specify the loss layer (note: CrossEntropyLoss already includes LogSoftMax())\n",
        "\n",
        "# ==================================================================\n",
        "# Modify the line below, experiment with different optimizers and parameters (such as learning rate)\n",
        "# ==================================================================\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=.01, weight_decay=2) # Specify optimizer and assign trainable parameters to it, weight_decay is L2 regularization strength (default: lr=1e-2, weight_decay=1e-4)\n",
        "\n",
        "# ==================================================================\n",
        "# Choose an appropriate number of training epochs\n",
        "# ==================================================================\n",
        "num_epochs = 5 \n",
        "\n",
        "def train(model, loader, num_epoch = num_epochs): # Train the model\n",
        "    print(\"Start training...\")\n",
        "    model.train() # Set the model to training mode\n",
        "    for i in range(num_epoch):\n",
        "        running_loss = []\n",
        "        for batch, label in tqdm(loader):\n",
        "            batch = batch.to(device)\n",
        "            label = label.to(device)\n",
        "            optimizer.zero_grad() # Clear gradients from the previous iteration\n",
        "            pred = model(batch) # This will call Network.forward() that you implement\n",
        "            loss = criterion(pred, label) # Calculate the loss\n",
        "            running_loss.append(loss.item())\n",
        "            loss.backward() # Backprop gradients to all tensors in the network\n",
        "            optimizer.step() # Update trainable weights\n",
        "        print(\"Epoch {} loss:{}\".format(i+1,np.mean(running_loss))) # Print the average loss for this epoch\n",
        "    print(\"Done!\")\n",
        "\n",
        "def evaluate(model, loader): # Evaluate accuracy on validation / test set\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    with torch.no_grad(): # Do not calculate grident to speed up computation\n",
        "        for batch, label in tqdm(loader):\n",
        "            batch = batch.to(device)\n",
        "            label = label.to(device)\n",
        "            pred = model(batch)\n",
        "            correct += (torch.argmax(pred,dim=1)==label).sum().item()\n",
        "    acc = correct/len(loader.dataset)\n",
        "    print(\"Evaluation accuracy: {}\".format(acc))\n",
        "    return acc\n",
        "    \n",
        "train(model, trainloader, num_epochs)\n",
        "print(\"Evaluate on test set\")\n",
        "evaluate(model, testloader)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed2d73b4a1c545d3b37c7d0d1804fff0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "child  6  was not frozen\n",
            "child  7  was not frozen\n",
            "child  8  was not frozen\n",
            "child  9  was not frozen\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/13441 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Start training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13441/13441 [02:52<00:00, 78.11it/s]\n",
            "  0%|          | 9/13441 [00:00<02:42, 82.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 loss:1.2501408548858117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13441/13441 [02:50<00:00, 78.65it/s]\n",
            "  0%|          | 8/13441 [00:00<02:54, 77.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 loss:1.2547251561708148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13441/13441 [02:54<00:00, 77.06it/s]\n",
            "  0%|          | 9/13441 [00:00<02:43, 82.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 loss:1.2458195106255574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13441/13441 [02:56<00:00, 76.17it/s]\n",
            "  0%|          | 9/13441 [00:00<02:41, 82.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4 loss:1.2491280822173598\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13441/13441 [02:50<00:00, 78.79it/s]\n",
            "  1%|          | 11/1622 [00:00<00:15, 102.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5 loss:1.2471687956681101\n",
            "Done!\n",
            "Evaluate on test set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1622/1622 [00:16<00:00, 97.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation accuracy: 0.5186555658341042\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5186555658341042"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYe8t07XsdXH"
      },
      "source": [
        ""
      ]
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 11885/13441 [36:37<04:24,  5.89it/s] "
     ]
    }
  ]
}